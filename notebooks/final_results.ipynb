{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa58452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs(\"../data/processed/figures\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22de32d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>1</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.114068</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  class  precision    recall  f1_score  support\n",
       "1  Baseline      1   0.828947  0.642857  0.724138     98.0\n",
       "3  Balanced      1   0.060811  0.918367  0.114068     98.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/model_comparison_metrics.csv\")\n",
    "df = df.rename(columns={\"Unnamed: 0\": \"class\"})\n",
    "df.columns = df.columns.str.replace(\"-\", \"_\")\n",
    "\n",
    "fraud = df[df[\"class\"].isin([1, \"1\"])].copy()\n",
    "fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c41138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(fraud))\n",
    "plt.figure()\n",
    "plt.scatter(fraud[\"recall\"], fraud[\"precision\"])\n",
    "for i, row in fraud.reset_index(drop=True).iterrows():\n",
    "    plt.text(row[\"recall\"], row[\"precision\"], row[\"model\"])\n",
    "\n",
    "plt.title(\"Precision vs Fraud (Fraud Class)\")\n",
    "plt.xlabel(\"Recall (Fraud)\")\n",
    "plt.ylabel(\"Precision (Fraud)\")\n",
    "plt.savefig(\"../data/processed/figures/precision_recall_fraud.png\", bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10386d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>min_precision_target</th>\n",
       "      <th>chosen_threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  min_precision_target  chosen_threshold\n",
       "0  Balanced                   0.5               1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_df = pd.read_csv(\"../data/processed/threshold_summary.csv\")\n",
    "threshold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ba9d8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fraud_precision</th>\n",
       "      <th>fraud_recall</th>\n",
       "      <th>fraud_f1_score</th>\n",
       "      <th>fraud_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Balanced</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.114068</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  fraud_precision  fraud_recall  fraud_f1_score  fraud_support\n",
       "1  Baseline         0.828947      0.642857        0.724138           98.0\n",
       "3  Balanced         0.060811      0.918367        0.114068           98.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary = fraud[[\"model\", \"precision\", \"recall\", \"f1_score\", \"support\"]].copy()\n",
    "final_summary = final_summary.rename(columns = {\n",
    "    \"precision\": \"fraud_precision\",\n",
    "    \"recall\": \"fraud_recall\",\n",
    "    \"f1_score\": \"fraud_f1_score\",\n",
    "    \"support\" : \"fraud_support\"\n",
    "})\n",
    "\n",
    "final_summary.to_csv(\"../data/processed/final_summary.csv\", index=False)\n",
    "final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a3a724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: data/processed/final_report.md\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "lines.append(\"# Relatório final - Detecção de fraudes\\n\")\n",
    "\n",
    "lines.append(\"## Conclusão\")\n",
    "lines.append(\"- Comparando Baseline vs Balanced, há um trade-off claro entre recall e precision na classe fraude.\")\n",
    "lines.append(\"- O modelo Balanced aumenta significativamente o recall, mas tende a gerar muitos falsos positivos.\")\n",
    "lines.append(\"- O threshold tuning foi aplicado para buscar um ponto de equilíbrio mais operacional.\\n\")\n",
    "\n",
    "lines.append(\"## Resultados (Classe Fraude)\")\n",
    "for _, row in final_summary.iterrows():\n",
    "    lines.append(f\"- **{row['model']}**: precision={row['fraud_precision']:.3f}, recall={row['fraud_recall']:.3f}, f1={row['fraud_f1_score']:.3f}, support={int(row['fraud_support'])}\")\n",
    "\n",
    "lines.append(\"\\n## Artefatos gerados\")\n",
    "lines.append(\"- `data/processed/final_summary.csv`\")\n",
    "lines.append(\"- `data/processed/figures/precision_recall_fraude.png`\")\n",
    "lines.append(\"- `data/processed/ai_conclusions.md` (interpretação via IA)\\n\")\n",
    "\n",
    "report_text = \"\\n\".join(lines)\n",
    "\n",
    "with open(\"../data/processed/final_report.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
